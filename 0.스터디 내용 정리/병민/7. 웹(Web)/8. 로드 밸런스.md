# 로드밸런스

이전에도 로드 밸런스에 대해서 많이 다뤘기 때문에, Nginx의 LB를 정리해두었습니다.

## Nginx 동작구조

- Nginx는 master/worker 구조로 동작합니다. master는 설정을 읽고 worker를 관리하며, worker는 실제로 요청을 처리합니다.
- 이벤트 기반 비동기 처리 모델로 많은 동시 연결을 효율적으로 처리합니다.
- HTTP 요청은 http 모듈에서 처리되고, upstream 블록으로 백엔드를 묶어 proxy_pass로 전달합니다.
- 중요한 포인트는 헤더 전달과 커넥션 재사용(keepalive), 그리고 proxy 관련 타임아웃 설정입니다.

## 용도

### 1. 로드 밸런싱

- Nginx는 L7(HTTP) 역프록시로 흔히 사용되며, stream 모듈로 L4(TCP/UDP) 처리도 가능합니다.
- 주로 트래픽 분산, SSL 종료, 정적 파일 서빙 분리, 세션 유지(필요 시)에 사용합니다.

#### 1. Round Robin

- 기본 방식으로 순차적으로 서버에 요청을 분배합니다.
- 서버 성능이 균등할 때 간단하고 유효합니다.
- 예시 (80에서 받아서 내부 8080으로 분산):

```nginx
http {
  upstream app_servers {
    server 10.0.0.11:8080;
    server 10.0.0.12:8080;
    server 10.0.0.13:8080;
    keepalive 32;
  }

  server {
    listen 80;
    server_name example.com;

    location / {
      proxy_pass http://app_servers;
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

      proxy_http_version 1.1;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection "upgrade";

      proxy_connect_timeout 5s;
      proxy_read_timeout 60s;
    }
  }
}
```

#### 2. Least Connection

- 현재 연결 수가 가장 적은 서버로 분배합니다. 장기 연결이 많은 서비스에 유리합니다.

```nginx
upstream app_servers {
  least_conn;
  server 10.0.0.11:8080;
  server 10.0.0.12:8080;
  server 10.0.0.13:8080;
}
```

#### 3. IP Hash

- 클라이언트 IP로 해시하여 같은 클라이언트가 같은 서버로 가도록 합니다. 간단한 스티키 세션 효과를 얻을 수 있습니다.
- 단점: NAT/프록시 환경에서는 의도와 다르게 동작할 수 있습니다.

```nginx
upstream app_servers {
  ip_hash;
  server 10.0.0.11:8080;
  server 10.0.0.12:8080;
  server 10.0.0.13:8080;
}
```

#### 4. Generic Hash

- Nginx 오픈소스는 기본으로 제공하지 않는 경우가 있어 Lua나 외부 모듈로 커스터마이즈할 수 있습니다.
- 쿠키 기반 스티키는 서드파티 모듈이나 Nginx Plus를 사용해 구현합니다.

### 2. 웹서버

- 정적 파일은 Nginx가 직접 서빙하는 것이 가장 직관적이고 빠릅니다. 백엔드(Java/Spring)는 API만 처리하도록 분리하면 리소스 소비를 줄일 수 있습니다.
- 일반적인 흐름은 프론트엔드 빌드 -> 빌드 파일(build/, dist/)을 서버에 복사 -> Nginx에서 해당 디렉토리를 루트로 서빙하는 방식입니다.

빌드/배포 예시 (로컬에서 빌드 -> 서버로 배포)

- React(create-react-app) 기준:

```bash
# 로컬에서
npm install
npm run build # 결과: build/ 디렉토리 생성

# 서버에 배포 (rsync 사용 예)
rsync -av --delete build/ user@server:/var/www/example.com/html/
# 또는 scp -r build/* user@server:/var/www/example.com/html/
```

- Vue, Angular 등은 dist/ 혹은 dist/<project>가 결과 디렉토리인 점도 동일합니다.

서버 쪽 설정 권장

- 정적 파일은 fingerprint(파일명 해시)를 사용해 long-term caching을 적용합니다.
- 캐시 만료는 이미지/JS/CSS는 1년(expires,max-age, immutable)으로 두고, index.html은 짧게 유지합니다.
- 권한은 /var/www/example.com/html 소유권과 권한을 nginx 프로세스가 읽을 수 있게 설정합니다.

Nginx 예시 (정적 서빙 + API 프록시)

- 가정: 정적 파일은 /var/www/example.com/html에 있고, API는 /api/로 시작해 내부 Java/Spring(8080)에 전달합니다. Nginx는 80/443에서 수신합니다.

```nginx
server {
  listen 80;
  server_name example.com;

  root /var/www/example.com/html; # index.html, static files
  index index.html;

  # 정적 리소스에 대해 긴 캐시 정책
  location ~* \.(?:css|js|jpg|jpeg|png|gif|ico|svg|woff2?|ttf)$ {
    try_files $uri =404;
    access_log off;
    expires 365d;
    add_header Cache-Control "public, max-age=31536000, immutable";
  }

  # API는 백엔드로 프록시
  location /api/ {
    proxy_pass http://app_servers; # upstream 정의 필요
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    proxy_connect_timeout 5s;
    proxy_read_timeout 60s;
  }

  # SPA: 없는 경로는 index.html로 포워딩
  location / {
    try_files $uri $uri/ /index.html;
  }
}
```

gzip, sendfile, 보안 설정 (nginx.conf에 추가)

```nginx
# http 블록 안
sendfile on;
tcp_nopush on;
tcp_nodelay on;
keepalive_timeout 65;
server_tokens off; # 에러 페이지에서 버전 정보 노출 금지

gzip on;
gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
gzip_min_length 256;
```

배포 파이프라인 팁

- CI(예: GitHub Actions, GitLab CI)에서 빌드 후 아티팩트를 서버에 rsync/ssh로 전송하면 안정적입니다.
- Blue-Green 배포나 S3+CloudFront 같은 CDN 조합도 고려하면 성능과 가용성이 향상합니다.

간단한 점검리스트

- index.html 접속 시 파일이 잘 내려오는지 확인합니다.
- /static/js, /static/css 같은 경로에서 파일이 200으로 내려오는지 확인합니다.
- API 호출이 /api/로 정상 포워딩 되는지 확인합니다.
- 빌드된 JS/CSS가 fingerprint 되어 있는지 확인합니다.
- gzip/brotli가 적용되어 있는지 확인합니다.

### 3. 프록시 서버

- Reverse proxy로서 요청을 받아 백엔드(여기선 Java/Spring 8080)로 전달합니다.
- proxy_set_header로 원본 Host와 클라이언트 IP를 전달해 로그와 인증에 도움이 되게 합니다.
- WebSocket 처리 시에는 proxy_http_version과 Upgrade/Connection 헤더를 설정합니다.

### 4. TCP/UDP 분산 처리

- stream 블록으로 TCP/UDP 레이어에서 라우팅을 구성할 수 있습니다.
- DB 커넥션 프록시나 TLS passthrough 같은 시나리오에 사용합니다.
- 예: TLS를 끝까지 백엔드에서 처리하고 싶다면 stream으로 passthrough를 구성합니다.

```nginx
stream {
  upstream tls_backend {
    server 10.0.0.11:443;
    server 10.0.0.12:443;
  }

  server {
    listen 443;
    proxy_pass tls_backend;
  }
}
```
